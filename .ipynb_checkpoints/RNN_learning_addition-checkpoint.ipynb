{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An implementation of sequence to sequence learning for performind addition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a RNN sequence to sequence (encoder-decoder) model to learn addition.\n",
    "\n",
    "The code are pretty much copied from\n",
    "https://github.com/keras-team/keras/blob/master/examples/addition_rnn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\puppy\\AppData\\Local\\conda\\conda\\envs\\DL\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "from six.moves import range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define classes for one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterTable(object):\n",
    "    ''' Given a set of characters:\n",
    "        + Encode them into a one hot interger representation\n",
    "        + Decode the one hot integer representation to their character output\n",
    "        + Decode a vector of probablities to their character output\n",
    "    '''\n",
    "    def __init__(self, chars):\n",
    "        ''' \n",
    "        # Arguments:\n",
    "            chars: Characters that can apeear in the input.\n",
    "        '''\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c,i) for i,c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i,c) for i,c in enumerate(self.chars))\n",
    "        \n",
    "    def encode(self, C, num_rows):\n",
    "        '''One hot encode given string C\n",
    "        #Arguments:\n",
    "            num_rows: number of rows int he returned on hot encoding.\n",
    "        '''\n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        for i,c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1\n",
    "        return x\n",
    "    \n",
    "    def decode(self, x, calc_argmax = True):\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return ''.join(self.indices_char[ic] for ic in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class colors:\n",
    "    ok = '\\033[92m'\n",
    "    fail = '\\033[91m'\n",
    "    close = '\\033[0m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate training/testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the model and dataset.\n",
    "TRAINING_SIZE = 100000\n",
    "DIGITS = 3\n",
    "REVERSE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n",
    "# int is DIGITS.\n",
    "MAXLEN = DIGITS + 1 + DIGITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = '0123456789+ '\n",
    "ctable = CharacterTable(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "0/100000 data has been generated\n",
      "5000/100000 data has been generated\n",
      "5000/100000 data has been generated\n",
      "5000/100000 data has been generated\n",
      "5000/100000 data has been generated\n",
      "10000/100000 data has been generated\n",
      "15000/100000 data has been generated\n",
      "15000/100000 data has been generated\n",
      "15000/100000 data has been generated\n",
      "15000/100000 data has been generated\n",
      "15000/100000 data has been generated\n",
      "15000/100000 data has been generated\n",
      "20000/100000 data has been generated\n",
      "20000/100000 data has been generated\n",
      "25000/100000 data has been generated\n",
      "25000/100000 data has been generated\n",
      "30000/100000 data has been generated\n",
      "30000/100000 data has been generated\n",
      "30000/100000 data has been generated\n",
      "30000/100000 data has been generated\n",
      "30000/100000 data has been generated\n",
      "30000/100000 data has been generated\n",
      "35000/100000 data has been generated\n",
      "35000/100000 data has been generated\n",
      "35000/100000 data has been generated\n",
      "35000/100000 data has been generated\n",
      "35000/100000 data has been generated\n",
      "40000/100000 data has been generated\n",
      "40000/100000 data has been generated\n",
      "40000/100000 data has been generated\n",
      "40000/100000 data has been generated\n",
      "40000/100000 data has been generated\n",
      "40000/100000 data has been generated\n",
      "40000/100000 data has been generated\n",
      "45000/100000 data has been generated\n",
      "45000/100000 data has been generated\n",
      "45000/100000 data has been generated\n",
      "50000/100000 data has been generated\n",
      "55000/100000 data has been generated\n",
      "55000/100000 data has been generated\n",
      "55000/100000 data has been generated\n",
      "60000/100000 data has been generated\n",
      "65000/100000 data has been generated\n",
      "65000/100000 data has been generated\n",
      "65000/100000 data has been generated\n",
      "65000/100000 data has been generated\n",
      "65000/100000 data has been generated\n",
      "65000/100000 data has been generated\n",
      "65000/100000 data has been generated\n",
      "65000/100000 data has been generated\n",
      "70000/100000 data has been generated\n",
      "70000/100000 data has been generated\n",
      "70000/100000 data has been generated\n",
      "70000/100000 data has been generated\n",
      "70000/100000 data has been generated\n",
      "75000/100000 data has been generated\n",
      "75000/100000 data has been generated\n",
      "75000/100000 data has been generated\n",
      "75000/100000 data has been generated\n",
      "80000/100000 data has been generated\n",
      "80000/100000 data has been generated\n",
      "80000/100000 data has been generated\n",
      "80000/100000 data has been generated\n",
      "80000/100000 data has been generated\n",
      "80000/100000 data has been generated\n",
      "80000/100000 data has been generated\n",
      "80000/100000 data has been generated\n",
      "80000/100000 data has been generated\n",
      "85000/100000 data has been generated\n",
      "85000/100000 data has been generated\n",
      "85000/100000 data has been generated\n",
      "85000/100000 data has been generated\n",
      "85000/100000 data has been generated\n",
      "85000/100000 data has been generated\n",
      "85000/100000 data has been generated\n",
      "85000/100000 data has been generated\n",
      "85000/100000 data has been generated\n",
      "85000/100000 data has been generated\n",
      "85000/100000 data has been generated\n",
      "85000/100000 data has been generated\n",
      "85000/100000 data has been generated\n",
      "85000/100000 data has been generated\n",
      "90000/100000 data has been generated\n",
      "90000/100000 data has been generated\n",
      "90000/100000 data has been generated\n",
      "90000/100000 data has been generated\n",
      "90000/100000 data has been generated\n",
      "95000/100000 data has been generated\n",
      "95000/100000 data has been generated\n",
      "95000/100000 data has been generated\n",
      "95000/100000 data has been generated\n",
      "95000/100000 data has been generated\n",
      "95000/100000 data has been generated\n",
      "95000/100000 data has been generated\n",
      "95000/100000 data has been generated\n",
      "95000/100000 data has been generated\n",
      "95000/100000 data has been generated\n",
      "95000/100000 data has been generated\n",
      "95000/100000 data has been generated\n",
      "95000/100000 data has been generated\n",
      "95000/100000 data has been generated\n",
      "95000/100000 data has been generated\n",
      "95000/100000 data has been generated\n",
      "95000/100000 data has been generated\n",
      "95000/100000 data has been generated\n",
      "95000/100000 data has been generated\n",
      "95000/100000 data has been generated\n",
      "95000/100000 data has been generated\n",
      "95000/100000 data has been generated\n",
      "95000/100000 data has been generated\n",
      "95000/100000 data has been generated\n",
      "95000/100000 data has been generated\n",
      "95000/100000 data has been generated\n",
      "95000/100000 data has been generated\n",
      "95000/100000 data has been generated\n",
      "95000/100000 data has been generated\n",
      "95000/100000 data has been generated\n",
      "Total addition question: 100000\n"
     ]
    }
   ],
   "source": [
    "print('Generating data...')\n",
    "questions = []\n",
    "expected = []\n",
    "seen = set()\n",
    "while len(questions)<TRAINING_SIZE:\n",
    "    if (len(questions)%10000==0):\n",
    "        print('%d/%d data has been generated' % (len(questions),TRAINING_SIZE))\n",
    "    f = lambda: int(''.join(np.random.choice(list('0123456789'))\n",
    "                           for i in range(np.random.randint(1,DIGITS+1))))\n",
    "    a, b = f(), f()\n",
    "    \n",
    "    #skip addition questions we've already seen\n",
    "    key = tuple(sorted((a,b)))\n",
    "    if key in seen:\n",
    "        continue\n",
    "    seen.add(key)\n",
    "    \n",
    "    #pad the data with spaces such that it is always MAXLEN\n",
    "    q = '{}+{}'.format(a,b)\n",
    "    query = q+' '*(MAXLEN-len(q))\n",
    "    ans = str(a+b)\n",
    "    ans += ''*(DIGITS+1-len(ans))\n",
    "    if REVERSE:\n",
    "        query = query[::-1]\n",
    "    questions.append(query)\n",
    "    expected.append(ans)\n",
    "print('Total addition question:', len(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorization..\n"
     ]
    }
   ],
   "source": [
    "print('vectorization..')\n",
    "x = np.zeros((len(questions), MAXLEN, len(chars)), dtype = np.bool)\n",
    "y = np.zeros((len(questions), DIGITS+1, len(chars)), dtype = np.bool)\n",
    "for i, sentence in enumerate(questions):\n",
    "    x[i] = ctable.encode(sentence, MAXLEN)\n",
    "for i, sentence in enumerate(expected):\n",
    "    y[i] = ctable.encode(sentence, DIGITS+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "(87500, 7, 12)\n",
      "(87500, 4, 12)\n",
      "Validation Data:\n",
      "(12500, 7, 12)\n",
      "(12500, 4, 12)\n"
     ]
    }
   ],
   "source": [
    "#shuffle (x,y)\n",
    "indices = np.arange(len(y))\n",
    "np.random.shuffle(indices)\n",
    "x = x[indices]\n",
    "y = y[indices]\n",
    "# Explicitly set apart 10% for validation data that we never train over.\n",
    "split_at = len(x) - len(x) // 8\n",
    "(x_train, x_val) = x[:split_at], x[split_at:]\n",
    "(y_train, y_val) = y[:split_at], y[split_at:]\n",
    "\n",
    "\n",
    "print('Training Data:')\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print('Validation Data:')\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try replacing GRU, or SimpleRNN.\n",
    "RNN = layers.CuDNNLSTM\n",
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 128\n",
    "LAYERS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cu_dnnlstm_3 (CuDNNLSTM)     (None, 128)               72704     \n",
      "_________________________________________________________________\n",
      "repeat_vector_5 (RepeatVecto (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_4 (CuDNNLSTM)     (None, 4, 128)            132096    \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_5 (CuDNNLSTM)     (None, 4, 128)            132096    \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 4, 12)             1548      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 4, 12)             0         \n",
      "=================================================================\n",
      "Total params: 338,444\n",
      "Trainable params: 338,444\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "\n",
    "#encode the input using a RNN, producing an output of HIDDEN_SIZE\n",
    "# Note: In a situation where your input sequences have a variable length,\n",
    "# use input_shape=(None, num_feature).\n",
    "model.add(RNN(HIDDEN_SIZE, input_shape = (MAXLEN, len(chars))))\n",
    "\n",
    "#As the decoder RNN's input, repeatedly provide with the last hidden state of\n",
    "# RNN for each time step. Repeat 'DIGITS + 1' times as that's the maximum\n",
    "# length of output, e.g., when DIGITS=3, max output is 999+999=1998.\n",
    "model.add(layers.RepeatVector(DIGITS + 1))\n",
    "\n",
    "# The decoder RNN could be multiple layers staked or a single layer\n",
    "for _ in range(LAYERS):\n",
    "    model.add(RNN(HIDDEN_SIZE, return_sequences = True))\n",
    "\n",
    "model.add(layers.TimeDistributed(layers.Dense(len(chars))))\n",
    "model.add(layers.Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer = 'adam',\n",
    "              metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Interation:1--------------------\n",
      "Train on 87500 samples, validate on 12500 samples\n",
      "Epoch 1/10\n",
      "87500/87500 [==============================] - 14s 162us/step - loss: 1.7537 - acc: 0.1453 - val_loss: 1.5984 - val_acc: 0.1804\n",
      "Epoch 2/10\n",
      "87500/87500 [==============================] - 13s 149us/step - loss: 1.3721 - acc: 0.2765 - val_loss: 1.2100 - val_acc: 0.3479\n",
      "Epoch 3/10\n",
      "87500/87500 [==============================] - 13s 147us/step - loss: 1.1202 - acc: 0.3783 - val_loss: 1.0328 - val_acc: 0.4060\n",
      "Epoch 4/10\n",
      "87500/87500 [==============================] - 13s 148us/step - loss: 0.8863 - acc: 0.4658 - val_loss: 0.7734 - val_acc: 0.5192\n",
      "Epoch 5/10\n",
      "87500/87500 [==============================] - 13s 148us/step - loss: 0.7379 - acc: 0.5250 - val_loss: 0.7165 - val_acc: 0.5314\n",
      "Epoch 6/10\n",
      "87500/87500 [==============================] - 13s 147us/step - loss: 0.6884 - acc: 0.5430 - val_loss: 0.7198 - val_acc: 0.5316\n",
      "Epoch 7/10\n",
      "87500/87500 [==============================] - 13s 150us/step - loss: 0.6587 - acc: 0.5540 - val_loss: 0.6647 - val_acc: 0.5460\n",
      "Epoch 8/10\n",
      "87500/87500 [==============================] - 13s 150us/step - loss: 0.6408 - acc: 0.5598 - val_loss: 0.6366 - val_acc: 0.5618\n",
      "Epoch 9/10\n",
      "87500/87500 [==============================] - 13s 149us/step - loss: 0.6242 - acc: 0.5663 - val_loss: 0.6082 - val_acc: 0.5731\n",
      "Epoch 10/10\n",
      "87500/87500 [==============================] - 13s 148us/step - loss: 0.6101 - acc: 0.5721 - val_loss: 0.6160 - val_acc: 0.5671\n",
      "Q 717+253 T 970  \u001b[91m☒\u001b[0m 9710\n",
      "Q 37+96   T 133  \u001b[91m☒\u001b[0m 1255\n",
      "Q 380+87  T 467  \u001b[91m☒\u001b[0m 4668\n",
      "Q 487+118 T 605  \u001b[91m☒\u001b[0m 6020\n",
      "Q 553+23  T 576  \u001b[91m☒\u001b[0m 5711\n",
      "--------------------Interation:2--------------------\n",
      "Train on 87500 samples, validate on 12500 samples\n",
      "Epoch 1/10\n",
      "87500/87500 [==============================] - 13s 148us/step - loss: 0.5937 - acc: 0.5795 - val_loss: 0.6093 - val_acc: 0.5734\n",
      "Epoch 2/10\n",
      "87500/87500 [==============================] - 13s 148us/step - loss: 0.5476 - acc: 0.5938 - val_loss: 0.5028 - val_acc: 0.6060\n",
      "Epoch 3/10\n",
      "87500/87500 [==============================] - 13s 149us/step - loss: 0.3847 - acc: 0.6523 - val_loss: 0.3076 - val_acc: 0.6895\n",
      "Epoch 4/10\n",
      "87500/87500 [==============================] - 13s 148us/step - loss: 0.1888 - acc: 0.7419 - val_loss: 0.1214 - val_acc: 0.7700\n",
      "Epoch 5/10\n",
      "87500/87500 [==============================] - 13s 149us/step - loss: 0.0930 - acc: 0.7785 - val_loss: 0.0677 - val_acc: 0.7856\n",
      "Epoch 6/10\n",
      "43520/87500 [=============>................] - ETA: 6s - loss: 0.0608 - acc: 0.7869"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-4c34df97299a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     model.fit(x_train,y_train,batch_size = BATCH_SIZE,\n\u001b[0;32m      4\u001b[0m                 \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                 validation_data = (x_val,y_val))\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m#select 5 samples fromthe validation set at random to visualize erros\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\DL\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\DL\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\DL\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\DL\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2478\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2479\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\DL\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\DL\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1140\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1141\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\DL\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1321\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\DL\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\DL\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1312\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\DL\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[0;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1420\u001b[1;33m             status, run_metadata)\n\u001b[0m\u001b[0;32m   1421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1422\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for iteration in range(1,50):\n",
    "    print('-'*20+'Interation:%d' % iteration + '-'*20)\n",
    "    model.fit(x_train,y_train,batch_size = BATCH_SIZE,\n",
    "                epochs = 10,\n",
    "                validation_data = (x_val,y_val))\n",
    "    \n",
    "    #select 5 samples fromthe validation set at random to visualize erros\n",
    "    #if iteration % 20!=0:\n",
    "    #    continue\n",
    "    for i in range(5):\n",
    "        ind = np.random.randint(0,len(x_val))\n",
    "        rowx,rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
    "        preds = model.predict_classes(rowx, verbose = 0)\n",
    "        q = ctable.decode(rowx[0])\n",
    "        correct = ctable.decode(rowy[0])\n",
    "        guess = ctable.decode(preds[0], calc_argmax = False)\n",
    "        print('Q', q[::-1] if REVERSE else q, end=' ')\n",
    "        print('T', correct, end=' ')\n",
    "        if correct == guess:\n",
    "            print(colors.ok+ '☑' + colors.close, end=' ')\n",
    "        else:\n",
    "            print(colors.fail + '☒' + colors.close, end=' ')\n",
    "        print(guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
